{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trapdoor Detection\n",
    "\n",
    "This notebook conducts the trapdoor detection on GMI, KED-MI, PLG-MI, and adversarial attacks.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. Conducted the Model Training and the Model Inversion metrics to produce reconstructed samples, as instructed in [README.md](https://github.com/ntuaislab/Trap-MID/blob/main/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from autoattack import AutoAttack\n",
    "\n",
    "sys.path.append(\"<PATH_TO_TRAP-MID_REPO>\") # e.g., \"../..\"\n",
    "\n",
    "import utils\n",
    "import classify\n",
    "import engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"<PATH_TO_CONFIG_FILE>\" # e.g., \"../../config/celeba/classify_trap.json\"\n",
    "args = utils.load_json(json_file=file)\n",
    "channel = args[\"dataset\"][\"channel\"]\n",
    "height = args[\"dataset\"][\"height\"]\n",
    "width = args[\"dataset\"][\"width\"]\n",
    "n_classes = args[\"dataset\"][\"n_classes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/celeba_trainset.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args['dataset']['train_file_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load 27018 images\n",
      "Initializing data loader took 14s\n",
      "Load 3009 images\n",
      "Initializing data loader took 1s\n"
     ]
    }
   ],
   "source": [
    "train_file = args['dataset']['train_file_path']\n",
    "trainset, trainloader = utils.init_dataloader(args, train_file, mode=\"test\")\n",
    "\n",
    "test_file = args['dataset']['test_file_path']\n",
    "testset, testloader = utils.init_dataloader(args, test_file, mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacky/.pyenv/versions/3.9.16/envs/plg/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jacky/.pyenv/versions/3.9.16/envs/plg/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): VGG16(\n",
       "    (feature): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (12): ReLU(inplace=True)\n",
       "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (16): ReLU(inplace=True)\n",
       "      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (19): ReLU(inplace=True)\n",
       "      (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (26): ReLU(inplace=True)\n",
       "      (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (32): ReLU(inplace=True)\n",
       "      (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (36): ReLU(inplace=True)\n",
       "      (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (39): ReLU(inplace=True)\n",
       "      (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (42): ReLU(inplace=True)\n",
       "      (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc_layer): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = classify.VGG16(n_classes)\n",
    "net = torch.nn.DataParallel(net).cuda()\n",
    "ckpt_path = '<MODEL_CHECKPOIINT_PATH>'\n",
    "ckp_T = torch.load(ckpt_path)\n",
    "state_dict = ckp_T['state_dict']\n",
    "net.load_state_dict(state_dict, strict=False)\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = False\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "triggers = torch.load(os.path.join(\n",
    "    os.path.dirname(os.path.dirname(ckpt_path)),\n",
    "    'trigger.tar'\n",
    ")).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signature Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/422 [00:00<?, ?it/s]/home/jacky/.pyenv/versions/3.9.16/envs/plg/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "100%|██████████| 422/422 [00:18<00:00, 22.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([27008, 2048]), torch.Size([27008, 2048]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_random_seed(0)\n",
    "alpha = args['trapdoor']['alpha']\n",
    "cnt = 0\n",
    "feat_clean = None\n",
    "feat_poisoned = None\n",
    "classwise_signature = torch.zeros((n_classes, 2048))\n",
    "classwise_cnt = torch.zeros((n_classes, 1))\n",
    "pred_clean = None\n",
    "pred_poisoned = None\n",
    "data_size = trainloader.batch_size * len(trainloader)\n",
    "num_backdoor, last_backdoor = divmod(data_size, n_classes)\n",
    "backdoor_iden_iterator = torch.hstack([\n",
    "    torch.arange(0, n_classes).repeat(num_backdoor),\n",
    "    torch.randperm(n_classes)[:last_backdoor]\n",
    "])[torch.randperm(data_size)].split(trainloader.batch_size)\n",
    "backdoor_iden_iterator2 = torch.hstack([\n",
    "    torch.arange(0, n_classes).repeat(num_backdoor),\n",
    "    torch.randperm(n_classes)[:last_backdoor]\n",
    "])[torch.randperm(data_size)].split(trainloader.batch_size)\n",
    "with torch.no_grad():\n",
    "    for i, ((img, iden), backdoor_iden, backdoor_iden2) in enumerate(zip(tqdm(trainloader), backdoor_iden_iterator, backdoor_iden_iterator2)):\n",
    "        img, iden = img.to(device), iden.to(device)\n",
    "        bs = img.size(0)\n",
    "        iden = iden.view(-1)\n",
    "        cnt += bs\n",
    "\n",
    "        key = torch.stack([triggers[j] for j in backdoor_iden], dim=0)\n",
    "        backdoor_img = engine.blend(img, key, alpha)\n",
    "        trigger_feats, trigger_out_prob = net(backdoor_img)\n",
    "\n",
    "        for i in range(bs):\n",
    "            classwise_signature[backdoor_iden[i]] += trigger_feats[i].cpu()\n",
    "            classwise_cnt[backdoor_iden[i]] += 1\n",
    "\n",
    "        feats, out_prob = net(img)\n",
    "\n",
    "        key = torch.stack([triggers[j] for j in backdoor_iden2], dim=0)\n",
    "        backdoor_img = engine.blend(img, key, alpha)\n",
    "        trigger_feats, trigger_out_prob = net(backdoor_img)\n",
    "\n",
    "        if feat_clean is None:\n",
    "            feat_clean = feats.cpu()\n",
    "            feat_poisoned = trigger_feats.cpu()\n",
    "            pred_clean = out_prob.argmax(dim=1).cpu()\n",
    "            pred_poisoned = trigger_out_prob.argmax(dim=1).cpu()\n",
    "        else:\n",
    "            feat_clean = torch.vstack([feat_clean, feats.cpu()])\n",
    "            feat_poisoned = torch.vstack([feat_poisoned, trigger_feats.cpu()])\n",
    "            pred_clean = torch.hstack([pred_clean, out_prob.argmax(dim=1).cpu()])\n",
    "            pred_poisoned = torch.hstack([pred_poisoned, trigger_out_prob.argmax(dim=1).cpu()])\n",
    "classwise_signature /= classwise_cnt\n",
    "feat_clean.shape, feat_poisoned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classwise_signature_unit = nn.functional.normalize(classwise_signature, p=2)\n",
    "feat_clean_unit = nn.functional.normalize(feat_clean, p=2)\n",
    "feat_poisoned_unit = nn.functional.normalize(feat_poisoned, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2503)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classwise_cos_clean = torch.tensor([feat_clean_unit[i] @ classwise_signature_unit[pred_clean[i]] for i in range(feat_clean_unit.shape[0])])\n",
    "classwise_cos_poisoned = torch.tensor([feat_poisoned_unit[i] @ classwise_signature_unit[pred_poisoned[i]] for i in range(feat_poisoned_unit.shape[0])])\n",
    "classwise_threshold = classwise_cos_clean.quantile(.95)\n",
    "classwise_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recovery Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load 30000 images\n",
      "Initializing data loader took 10s\n"
     ]
    }
   ],
   "source": [
    "gan_file = '<PATH_TO_GAN_SET_FILE>' # e.g., \"../../data/celeba_ganset.txt\"\n",
    "ganset, ganloader = utils.init_dataloader(args, gan_file, mode=\"gan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:16<00:00, 28.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.1051)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_gan = None\n",
    "pred_gan = None\n",
    "with torch.no_grad():\n",
    "    for i, img in enumerate(tqdm(ganloader)):\n",
    "        img = img.to(device)\n",
    "\n",
    "        feats, out_prob = net(img)\n",
    "\n",
    "        if feat_gan is None:\n",
    "            feat_gan = feats.cpu()\n",
    "            pred_gan = out_prob.argmax(dim=1).cpu()\n",
    "        else:\n",
    "            feat_gan = torch.vstack([feat_gan, feats.cpu()])\n",
    "            pred_gan = torch.hstack([pred_gan, out_prob.argmax(dim=1).cpu()])\n",
    "feat_gan_unit = nn.functional.normalize(feat_gan, p=2)\n",
    "feat_gan.shape, feat_gan_unit.shape\n",
    "\n",
    "classwise_cos_gan = torch.tensor([feat_gan_unit[i] @ classwise_signature_unit[pred_gan[i]] for i in range(feat_gan_unit.shape[0])])\n",
    "classwise_cos_gan.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recovered_path = '<PATH_TO_ATTACK_RESULTS>/all_imgs'\n",
    "recovered = torchvision.datasets.ImageFolder(root=recovered_path, transform=transforms.ToTensor())\n",
    "recovered_loader = torch.utils.data.DataLoader(recovered, 250)\n",
    "len(recovered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.6702)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_recovered = None\n",
    "iden_recovered = None\n",
    "pred_recovered = None\n",
    "with torch.no_grad():\n",
    "    for i, (img, iden) in enumerate(tqdm(recovered_loader)):\n",
    "        img = img.to(device)\n",
    "\n",
    "        feats, out_prob = net(img)\n",
    "\n",
    "        if feat_recovered is None:\n",
    "            feat_recovered = feats.cpu()\n",
    "            iden_recovered = iden.cpu()\n",
    "            pred_recovered = out_prob.argmax(dim=1).cpu()\n",
    "        else:\n",
    "            feat_recovered = torch.vstack([feat_recovered, feats.cpu()])\n",
    "            iden_recovered = torch.hstack([iden_recovered, iden.cpu()])\n",
    "            pred_recovered = torch.hstack([pred_recovered, out_prob.argmax(dim=1).cpu()])\n",
    "feat_recovered_unit = nn.functional.normalize(feat_recovered, p=2)\n",
    "classwise_cos_recovered = torch.tensor([feat_recovered_unit[i] @ classwise_signature_unit[pred_recovered[i]] for i in range(feat_recovered_unit.shape[0])])\n",
    "classwise_cos_recovered.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:01<00:00, 25.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([3008, 3, 64, 64]), torch.Size([3008]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_img = None\n",
    "all_iden = None\n",
    "for img, iden in tqdm(testloader):\n",
    "    if all_img is None:\n",
    "        all_img = img\n",
    "        all_iden = iden\n",
    "    else:\n",
    "        all_img = torch.vstack([all_img, img])\n",
    "        all_iden = torch.hstack([all_iden, iden])\n",
    "all_img.shape, all_iden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting parameters for standard version\n",
      "using standard version including apgd-ce, apgd-t, fab-t, square.\n",
      "initial accuracy: 81.62%\n",
      "apgd-ce - 1/5 - 512 out of 512 successfully perturbed\n",
      "apgd-ce - 2/5 - 512 out of 512 successfully perturbed\n",
      "apgd-ce - 3/5 - 512 out of 512 successfully perturbed\n",
      "apgd-ce - 4/5 - 512 out of 512 successfully perturbed\n",
      "apgd-ce - 5/5 - 407 out of 407 successfully perturbed\n",
      "robust accuracy after APGD-CE: 0.00% (total time 61.5 s)\n",
      "max Linf perturbation: 0.03137, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
      "robust accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "eps_inf = 8/255\n",
    "adv_inf = AutoAttack(\n",
    "    lambda x: net(x)[1],\n",
    "    norm='Linf', eps=eps_inf, version='standard'\n",
    ")\n",
    "x_adv_inf = adv_inf.run_standard_evaluation(all_img, all_iden, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting parameters for standard version\n",
      "using standard version including apgd-ce, apgd-t, fab-t, square.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial accuracy: 81.62%\n",
      "apgd-ce - 1/5 - 512 out of 512 successfully perturbed\n",
      "apgd-ce - 2/5 - 512 out of 512 successfully perturbed\n",
      "apgd-ce - 3/5 - 512 out of 512 successfully perturbed\n",
      "apgd-ce - 4/5 - 512 out of 512 successfully perturbed\n",
      "apgd-ce - 5/5 - 407 out of 407 successfully perturbed\n",
      "robust accuracy after APGD-CE: 0.00% (total time 62.4 s)\n",
      "max L2 perturbation: 0.50000, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
      "robust accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "eps_l2 = 0.5\n",
    "adv_l2 = AutoAttack(\n",
    "    lambda x: net(x)[1],\n",
    "    norm='L2', eps=eps_l2, version='standard'\n",
    ")\n",
    "x_adv_l2 = adv_l2.run_standard_evaluation(all_img, all_iden, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    feat_test, out_test = net(all_img)\n",
    "    feat_adv_inf, out_adv_inf = net(x_adv_inf)\n",
    "    feat_adv_l2, out_adv_l2 = net(x_adv_l2)\n",
    "feat_test_unit = nn.functional.normalize(feat_test.cpu(), p=2)\n",
    "feat_adv_inf_unit = nn.functional.normalize(feat_adv_inf.cpu(), p=2)\n",
    "feat_adv_l2_unit = nn.functional.normalize(feat_adv_l2.cpu(), p=2)\n",
    "pred_test = out_test.argmax(dim=1).cpu()\n",
    "pred_adv_inf = out_adv_inf.argmax(dim=1).cpu()\n",
    "pred_adv_l2 = out_adv_l2.argmax(dim=1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1328), tensor(0.4386), tensor(0.6708))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classwise_cos_test = torch.tensor([feat_test_unit[i] @ classwise_signature_unit[pred_test[i]] for i in range(feat_test_unit.shape[0])])\n",
    "classwise_cos_adv_inf = torch.tensor([feat_adv_inf_unit[i] @ classwise_signature_unit[pred_adv_inf[i]] for i in range(feat_adv_inf_unit.shape[0])])\n",
    "classwise_cos_adv_l2 = torch.tensor([feat_adv_l2_unit[i] @ classwise_signature_unit[pred_adv_l2[i]] for i in range(feat_adv_l2_unit.shape[0])])\n",
    "classwise_cos_test.mean(), classwise_cos_adv_inf.mean(), classwise_cos_adv_l2.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = '<PATH_TO_SIGNATURE_RESULTS>'\n",
    "\n",
    "# Signature & Signature Threshold\n",
    "torch.save(classwise_signature_unit, f'{result_dir}/classwise_signature_unit.tar')\n",
    "torch.save(classwise_threshold, f'{result_dir}/classwise_threshold.tar')\n",
    "\n",
    "# Training Set\n",
    "torch.save(classwise_cos_clean, f'{result_dir}/classwise_cos_clean.tar')\n",
    "torch.save(classwise_cos_poisoned, f'{result_dir}/classwise_cos_poisoned.tar')\n",
    "\n",
    "# Public Set & Recovered Set\n",
    "attack = 'plgmi' # gmi, kedmi, plgmi\n",
    "torch.save(classwise_cos_gan, f'{result_dir}/classwise_cos_gan.tar')\n",
    "torch.save(classwise_cos_recovered, f'{result_dir}/classwise_cos_{attack}.tar')\n",
    "\n",
    "# Testing Set & Adversarial Set\n",
    "torch.save(classwise_cos_test, f'{result_dir}/classwise_cos_test.tar')\n",
    "torch.save(classwise_cos_adv_inf, f'{result_dir}/classwise_cos_adv_inf.tar')\n",
    "torch.save(classwise_cos_adv_l2, f'{result_dir}/classwise_cos_adv_l2.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
